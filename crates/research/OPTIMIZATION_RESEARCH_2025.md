# ForgeCode Optimization Research 2025

## Overview

Layer3/Layer4 ìµœì í™” ë° ë¶€ì¡±í•œ ë¶€ë¶„ì— ëŒ€í•œ ì—°êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤.

---

## 1. Layer4 í˜„í™© ë¶„ì„

### 1.1 í˜„ì¬ êµ¬í˜„ ìƒíƒœ

```
Layer4-cli/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs
â”‚   â”œâ”€â”€ cli.rs              âœ… ê¸°ë³¸ êµ¬í˜„
â”‚   â””â”€â”€ tui/
â”‚       â”œâ”€â”€ app.rs          âœ… Ratatui ê¸°ë°˜ TUI
â”‚       â”œâ”€â”€ event.rs        âœ… ì´ë²¤íŠ¸ í•¸ë“¤ë§
â”‚       â”œâ”€â”€ theme.rs        âœ… í…Œë§ˆ
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ input.rs    âœ… InputBox
â”‚       â”‚   â””â”€â”€ message_list.rs  âœ… ChatMessage
â”‚       â””â”€â”€ pages/
â”‚           â””â”€â”€ chat.rs     âš ï¸ ë¶€ë¶„ êµ¬í˜„ (auto_approve ì‚¬ìš© ì¤‘)
```

### 1.2 ë¯¸êµ¬í˜„ í•µì‹¬ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ìƒíƒœ | Layer1 Trait |
|------|------|--------------|
| Permission Modal | âŒ ë¯¸êµ¬í˜„ | `PermissionDelegate` |
| Task Progress Display | âŒ ë¯¸êµ¬í˜„ | `TaskObserver` |
| Error Display Component | âŒ ë¯¸êµ¬í˜„ | - |
| Tool Execution Feedback | âš ï¸ ë¶€ë¶„ | - |

### 1.3 í•„ìš”í•œ êµ¬í˜„

#### PermissionDelegate êµ¬í˜„
```rust
// Layer4-cli/src/tui/components/permission.rs (ì‹ ê·œ)

pub struct PermissionModal {
    tool_name: String,
    action: PermissionAction,
    description: String,
    risk_score: u8,
    selected_option: usize,
}

#[async_trait]
impl PermissionDelegate for TuiPermissionDelegate {
    async fn request_permission(
        &self,
        tool_name: &str,
        action: &PermissionAction,
        description: &str,
        risk_score: u8,
    ) -> PermissionResponse {
        // TUI ëª¨ë‹¬ í‘œì‹œ
        // ì‚¬ìš©ì ì„ íƒ ëŒ€ê¸°
        // AllowOnce/AllowSession/AllowPermanent/Deny/DenyPermanent ë°˜í™˜
    }
}
```

#### TaskObserver êµ¬í˜„
```rust
// Layer4-cli/src/tui/components/progress.rs (ì‹ ê·œ)

pub struct TaskProgressWidget {
    tasks: HashMap<String, TaskInfo>,
}

impl TaskObserver for TuiTaskObserver {
    fn on_state_change(&self, task_id: &str, state: TaskState) {
        // ìƒíƒœ ë³€ê²½ UI ì—…ë°ì´íŠ¸
    }
    
    fn on_progress(&self, task_id: &str, progress: f32, message: &str) {
        // ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸
    }
    
    fn on_complete(&self, task_id: &str, result: &TaskResult) {
        // ì™„ë£Œ í‘œì‹œ
    }
}
```

---

## 2. Layer3 ìµœì í™” ì—°êµ¬

### 2.1 Context Engineering (ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§)

**ë¬¸ì œì **: LLMì€ ì»¨í…ìŠ¤íŠ¸ê°€ ì»¤ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ì €í•˜ë¨ ("Context Rot")

**ìµœì í™” ì „ëµ**:

#### 2.1.1 Prompt Caching
```rust
/// í”„ë¡¬í”„íŠ¸ ìºì‹± ì‹œìŠ¤í…œ
pub struct PromptCache {
    /// ì •ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìºì‹œ (hash -> cached_tokens)
    static_cache: HashMap<u64, CachedPrompt>,
    
    /// ìºì‹œ íˆíŠ¸ìœ¨ í†µê³„
    stats: CacheStats,
}

impl PromptCache {
    /// ìºì‹œëœ í† í°ì€ 75% ì €ë ´
    /// Docker ë ˆì´ì–´ì²˜ëŸ¼ ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì¬ì²˜ë¦¬
    pub fn get_or_compute(&mut self, prompt: &str) -> CachedPrompt {
        let hash = self.compute_hash(prompt);
        
        if let Some(cached) = self.static_cache.get(&hash) {
            self.stats.hits += 1;
            return cached.clone();
        }
        
        self.stats.misses += 1;
        let cached = CachedPrompt::new(prompt);
        self.static_cache.insert(hash, cached.clone());
        cached
    }
}
```

#### 2.1.2 Context Compaction (ADK ìŠ¤íƒ€ì¼)
```rust
/// ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ì‹œìŠ¤í…œ
pub struct ContextCompactor {
    /// ì••ì¶• ì„ê³„ê°’ (ì˜ˆ: 80% ì‚¬ìš© ì‹œ ì••ì¶•)
    threshold: f32,
    
    /// ìŠ¬ë¼ì´ë”© ìœˆë„ìš° í¬ê¸°
    window_size: usize,
}

impl ContextCompactor {
    /// ADK ìŠ¤íƒ€ì¼: ì˜¤ë˜ëœ ì´ë²¤íŠ¸ë¥¼ LLMìœ¼ë¡œ ìš”ì•½
    pub async fn compact(&self, session: &mut SessionContext) -> Result<()> {
        if session.token_usage_ratio() < self.threshold {
            return Ok(());
        }
        
        // ìµœê·¼ Nê°œ ë©”ì‹œì§€ ìœ ì§€
        let keep_recent = self.window_size;
        let to_summarize = session.messages.len().saturating_sub(keep_recent);
        
        if to_summarize < 5 {
            return Ok(());
        }
        
        // ì˜¤ë˜ëœ ë©”ì‹œì§€ ìš”ì•½
        let old_messages: Vec<_> = session.messages.drain(..to_summarize).collect();
        let summary = self.summarize(&old_messages).await?;
        
        // ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
        session.messages.insert(0, Message::Summary(summary));
        
        Ok(())
    }
}
```

#### 2.1.3 Token-Efficient Serialization
```rust
/// í† í° íš¨ìœ¨ì  ì§ë ¬í™”
/// ë¬¸ì œ: JSON í¬ë§·íŒ…ì´ 40-70% í† í°ì„ ë‚­ë¹„
pub struct TokenEfficientSerializer;

impl TokenEfficientSerializer {
    /// íŒŒì¼ ë‚´ìš© ì••ì¶•
    pub fn serialize_file_content(content: &str, max_lines: usize) -> String {
        let lines: Vec<_> = content.lines().collect();
        
        if lines.len() <= max_lines {
            return content.to_string();
        }
        
        // ì•/ë’¤ ì¼ë¶€ë§Œ í¬í•¨ + ìƒëµ í‘œì‹œ
        let half = max_lines / 2;
        let mut result = lines[..half].join("\n");
        result.push_str(&format!("\n... ({} lines omitted) ...\n", lines.len() - max_lines));
        result.push_str(&lines[lines.len() - half..].join("\n"));
        result
    }
    
    /// ë„êµ¬ ê²°ê³¼ ì••ì¶•
    pub fn compress_tool_result(result: &ToolResult) -> String {
        // ë¶ˆí•„ìš”í•œ ê³µë°±, ì¤‘ë³µ ì •ë³´ ì œê±°
        // í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
    }
}
```

### 2.2 Parallel Tool Execution

**ì—°êµ¬ ê²°ê³¼**: ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ 12-22% ë ˆì´í„´ì‹œ ê°ì†Œ

```rust
/// ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰ ìµœì í™”
pub struct ParallelToolExecutor {
    /// ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜
    max_concurrent: usize,
}

impl ParallelToolExecutor {
    /// ë…ë¦½ì ì¸ ë„êµ¬ í˜¸ì¶œì€ ë³‘ë ¬ ì‹¤í–‰
    pub async fn execute_parallel(
        &self,
        ctx: &AgentContext,
        tool_calls: &[ToolCall],
    ) -> Vec<ToolExecutionResult> {
        // ì˜ì¡´ì„± ë¶„ì„
        let (independent, dependent) = self.analyze_dependencies(tool_calls);
        
        let mut results = Vec::new();
        
        // ë…ë¦½ì  í˜¸ì¶œì€ ë³‘ë ¬
        if !independent.is_empty() {
            let futures: Vec<_> = independent.iter()
                .map(|tc| ctx.execute_tool(&tc.name, tc.arguments.clone()))
                .collect();
            
            let parallel_results = futures::future::join_all(futures).await;
            results.extend(parallel_results.into_iter().filter_map(|r| r.ok()));
        }
        
        // ì˜ì¡´ì  í˜¸ì¶œì€ ìˆœì°¨
        for tc in dependent {
            if let Ok(result) = ctx.execute_tool(&tc.name, tc.arguments.clone()).await {
                results.push(result);
            }
        }
        
        results
    }
    
    fn analyze_dependencies(&self, calls: &[ToolCall]) -> (Vec<&ToolCall>, Vec<&ToolCall>) {
        // íŒŒì¼ ê²½ë¡œ ê¸°ë°˜ ì˜ì¡´ì„± ë¶„ì„
        // ì˜ˆ: write â†’ read ê°™ì€ íŒŒì¼ì´ë©´ ìˆœì°¨ ì‹¤í–‰
        let mut independent = Vec::new();
        let mut dependent = Vec::new();
        
        let mut written_paths: HashSet<String> = HashSet::new();
        
        for call in calls {
            let paths = self.extract_paths(call);
            
            // ì´ì „ì— ì“´ íŒŒì¼ì„ ì½ìœ¼ë©´ ì˜ì¡´ì 
            if paths.iter().any(|p| written_paths.contains(p)) {
                dependent.push(call);
            } else {
                independent.push(call);
            }
            
            // write ë„êµ¬ë©´ ê²½ë¡œ ì¶”ì 
            if call.name == "write" || call.name == "edit" {
                for path in paths {
                    written_paths.insert(path);
                }
            }
        }
        
        (independent, dependent)
    }
}
```

### 2.3 Model Selection Optimization

**OpenCode ì ‘ê·¼ë²•**: ì‘ì—… ìœ í˜•ì— ë”°ë¼ ëª¨ë¸ ì „í™˜

```rust
/// ëª¨ë¸ ì„ íƒ ìµœì í™”
pub struct ModelSelector {
    /// ì¶”ë¡ ìš© ëª¨ë¸ (Claude, o1)
    reasoning_model: ModelSpec,
    
    /// ì‹¤í–‰ìš© ëª¨ë¸ (GPT-4o, Codestral)
    execution_model: ModelSpec,
    
    /// ë¹ ë¥¸ ì‘ì—…ìš© ëª¨ë¸ (GPT-4o-mini, Haiku)
    fast_model: ModelSpec,
}

impl ModelSelector {
    pub fn select_for_task(&self, task_type: TaskType) -> &ModelSpec {
        match task_type {
            // ë³µì¡í•œ ì•„í‚¤í…ì²˜ ê²°ì •
            TaskType::Planning | TaskType::Architecture => &self.reasoning_model,
            
            // ì½”ë“œ ì‘ì„±/ë¦¬íŒ©í† ë§
            TaskType::Coding | TaskType::Refactoring => &self.execution_model,
            
            // ê°„ë‹¨í•œ ê²€ìƒ‰/ìš”ì•½
            TaskType::Search | TaskType::Summary => &self.fast_model,
        }
    }
}

pub enum TaskType {
    Planning,
    Architecture,
    Coding,
    Refactoring,
    Search,
    Summary,
    Debug,
}
```

### 2.4 Streaming & Incremental Context

**DuoAttention ì ‘ê·¼ë²•**: Streaming Heads + Retrieval Heads

```rust
/// ìŠ¤íŠ¸ë¦¬ë° ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
pub struct StreamingContext {
    /// ê³ ì • KV ìºì‹œ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì¤‘ìš” ì»¨í…ìŠ¤íŠ¸)
    fixed_context: Vec<Message>,
    
    /// ìŠ¤íŠ¸ë¦¬ë° ìœˆë„ìš° (ìµœê·¼ ë©”ì‹œì§€)
    streaming_window: VecDeque<Message>,
    
    /// ìœˆë„ìš° í¬ê¸°
    window_size: usize,
}

impl StreamingContext {
    pub fn add_message(&mut self, message: Message) {
        self.streaming_window.push_back(message);
        
        // ìœˆë„ìš° í¬ê¸° ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ê²ƒ ì œê±°
        while self.streaming_window.len() > self.window_size {
            let old = self.streaming_window.pop_front();
            // ì¤‘ìš”í•œ ë©”ì‹œì§€ëŠ” ìš”ì•½í•˜ì—¬ fixed_contextë¡œ ì´ë™
            if self.is_important(&old) {
                self.fixed_context.push(self.summarize(&old));
            }
        }
    }
    
    pub fn get_context(&self) -> Vec<&Message> {
        self.fixed_context.iter()
            .chain(self.streaming_window.iter())
            .collect()
    }
}
```

---

## 3. ì•„í‚¤í…ì²˜ ê°­ ë¶„ì„

### 3.1 í˜„ì¬ ë¶€ì¡±í•œ ë¶€ë¶„

| ì˜ì—­ | í˜„ì¬ ìƒíƒœ | í•„ìš”í•œ êµ¬í˜„ | ìš°ì„ ìˆœìœ„ |
|------|----------|------------|---------|
| **Permission UI** | auto_approve ì‚¬ìš© | TUI ëª¨ë‹¬ | ğŸ”´ HIGH |
| **Prompt Caching** | ì—†ìŒ | í•´ì‹œ ê¸°ë°˜ ìºì‹± | ğŸ”´ HIGH |
| **Context Compaction** | Layer2-taskì— ê¸°ë³¸ êµ¬ì¡° | ì‹¤ì œ êµ¬í˜„ | ğŸ”´ HIGH |
| **Parallel Execution** | ê¸°ë³¸ ì§€ì› | ì˜ì¡´ì„± ë¶„ì„ ì¶”ê°€ | ğŸŸ¡ MEDIUM |
| **Model Selection** | ë‹¨ì¼ ëª¨ë¸ | ì‘ì—…ë³„ ëª¨ë¸ ì „í™˜ | ğŸŸ¡ MEDIUM |
| **Task Progress** | ì—†ìŒ | TUI ìœ„ì ¯ | ğŸŸ¡ MEDIUM |
| **Token Serialization** | ê¸°ë³¸ JSON | ì••ì¶• ì§ë ¬í™” | ğŸŸ¢ LOW |

### 3.2 Layer2-task SubAgent ê°­

í˜„ì¬ `crates/Layer2-task/src/subagent/` êµ¬ì¡°:
```
subagent/
â”œâ”€â”€ types.rs      âœ… ê¸°ë³¸ íƒ€ì…
â”œâ”€â”€ config.rs     âœ… ì„¤ì •
â”œâ”€â”€ context.rs    âš ï¸ ë¶€ë¶„ (ContextWindow, PreRot)
â”œâ”€â”€ handoff.rs    âš ï¸ ë¶€ë¶„ (Amp ìŠ¤íƒ€ì¼ í•¸ë“œì˜¤í”„)
â””â”€â”€ manager.rs    âš ï¸ ë¶€ë¶„ (ë§¤ë‹ˆì €)
```

**í•„ìš”í•œ ì¶”ê°€ êµ¬í˜„**:
1. `ContextCompactor` ì‹¤ì œ LLM ìš”ì•½ ë¡œì§
2. `PreRotation` (ì‚¬ì „ ì••ì¶•) ì‹¤í–‰ ë¡œì§
3. `HandoffManager` ì™„ì „í•œ êµ¬í˜„

### 3.3 Layer3 ì—ì´ì „íŠ¸ ê°­

Layer3-agentëŠ” ì•„ì§ ìƒì„±ë˜ì§€ ì•ŠìŒ. í•„ìš”í•œ ê²ƒ:
1. `prompts/` ë””ë ‰í† ë¦¬ì™€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤
2. `PromptComposer` êµ¬í˜„
3. `AgentExecutor` ë©”ì¸ ë£¨í”„
4. `AgentRegistry` ì—ì´ì „íŠ¸ ì„¤ì • ê´€ë¦¬

---

## 4. ìµœì‹  ê¸°ìˆ  ì ìš© ì œì•ˆ

### 4.1 Prompt Caching (Claude ìŠ¤íƒ€ì¼)

```rust
/// Claude API í”„ë¡¬í”„íŠ¸ ìºì‹± í™œìš©
pub struct ClaudePromptCache {
    /// ìºì‹œ ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë¸”ë¡ ë§ˆí‚¹
    cache_control: CacheControl,
}

impl ClaudePromptCache {
    /// ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— cache_control ë§ˆí‚¹
    pub fn mark_cacheable(&self, messages: &mut Vec<Message>) {
        // ì²« ë²ˆì§¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í•­ìƒ ìºì‹œ
        if let Some(first) = messages.first_mut() {
            first.cache_control = Some(CacheControl::Ephemeral);
        }
        
        // ë„êµ¬ ì •ì˜ë„ ìºì‹œ
        for msg in messages.iter_mut() {
            if msg.is_tool_definition() {
                msg.cache_control = Some(CacheControl::Ephemeral);
            }
        }
    }
}
```

### 4.2 Git Worktree ê¸°ë°˜ ë³‘ë ¬ ì—ì´ì „íŠ¸

```rust
/// Git Worktree ê¸°ë°˜ ë³‘ë ¬ ì‘ì—…
pub struct WorktreeParallelizer {
    /// ê¸°ë³¸ ì €ì¥ì†Œ ê²½ë¡œ
    base_repo: PathBuf,
}

impl WorktreeParallelizer {
    /// ë³‘ë ¬ ì‘ì—…ì„ ìœ„í•œ worktree ìƒì„±
    pub async fn create_worktree(&self, task_id: &str) -> Result<PathBuf> {
        let worktree_path = self.base_repo
            .parent()
            .unwrap()
            .join(format!(".worktrees/{}", task_id));
        
        let branch_name = format!("agent/{}", task_id);
        
        // git worktree add
        Command::new("git")
            .args(["worktree", "add", "-b", &branch_name])
            .arg(&worktree_path)
            .current_dir(&self.base_repo)
            .output()
            .await?;
        
        Ok(worktree_path)
    }
    
    /// ì‘ì—… ì™„ë£Œ í›„ ë³‘í•©
    pub async fn merge_worktree(&self, task_id: &str) -> Result<()> {
        let branch_name = format!("agent/{}", task_id);
        
        // git merge
        Command::new("git")
            .args(["merge", "--no-ff", &branch_name])
            .current_dir(&self.base_repo)
            .output()
            .await?;
        
        // worktree ì •ë¦¬
        self.cleanup_worktree(task_id).await
    }
}
```

### 4.3 Shared Memory for Agents

```rust
/// ì—ì´ì „íŠ¸ ê°„ ê³µìœ  ë©”ëª¨ë¦¬
pub struct SharedAgentMemory {
    /// ê³µìœ  ì§€ì‹ (markdown íŒŒì¼ ê¸°ë°˜)
    knowledge_file: PathBuf,
    
    /// ì ê¸ˆ
    lock: Arc<RwLock<()>>,
}

impl SharedAgentMemory {
    /// ì§€ì‹ ì¶”ê°€
    pub async fn add_knowledge(&self, fact: &str) -> Result<()> {
        let _guard = self.lock.write().await;
        
        let mut content = fs::read_to_string(&self.knowledge_file).await
            .unwrap_or_default();
        
        content.push_str(&format!("\n- {}", fact));
        
        fs::write(&self.knowledge_file, content).await?;
        Ok(())
    }
    
    /// ì§€ì‹ ì¡°íšŒ
    pub async fn get_knowledge(&self) -> Result<String> {
        let _guard = self.lock.read().await;
        fs::read_to_string(&self.knowledge_file).await
            .map_err(Into::into)
    }
}
```

---

## 5. êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: í•µì‹¬ ê¸°ëŠ¥ (HIGH)
1. âœ… Layer4 `PermissionDelegate` TUI êµ¬í˜„
2. âœ… Layer3 `PromptComposer` ê¸°ë³¸ êµ¬í˜„
3. âœ… Prompt Caching ì‹œìŠ¤í…œ
4. âœ… Context Compaction ì‹¤ì œ êµ¬í˜„

### Phase 2: ìµœì í™” (MEDIUM)
1. ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰ ì˜ì¡´ì„± ë¶„ì„
2. ëª¨ë¸ ì„ íƒ ìµœì í™”
3. Layer4 `TaskObserver` TUI êµ¬í˜„
4. Token-efficient ì§ë ¬í™”

### Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ (LOW)
1. Git Worktree ë³‘ë ¬ ì‘ì—…
2. ì—ì´ì „íŠ¸ ê°„ ê³µìœ  ë©”ëª¨ë¦¬
3. ìë™ ëª¨ë¸ ì „í™˜

---

## 6. ì°¸ê³  ìë£Œ

### Context Engineering
- [Context Window Management Strategies](https://www.getmaxim.ai/articles/context-window-management-strategies-for-long-context-ai-agents-and-chatbots/)
- [Context Engineering for AI Agents](https://www.flowhunt.io/blog/context-engineering-ai-agents-token-optimization/)
- [JetBrains Efficient Context Management](https://blog.jetbrains.com/research/2025/12/efficient-context-management/)

### Agent Architecture
- [Claude Code vs OpenCode](https://www.infralovers.com/blog/2026-01-29-claude-code-vs-opencode/)
- [Optimizing Agentic Coding](https://research.aimultiple.com/agentic-coding/)
- [Multi-Agent Parallel Execution](https://skywork.ai/blog/agent/multi-agent-parallel-execution-running-multiple-ai-agents-simultaneously/)

### Token Optimization
- [Token Optimization Strategies](https://medium.com/elementor-engineers/optimizing-token-usage-in-agent-based-assistants-ffd1822ece9c)
- [DuoAttention Paper](https://proceedings.iclr.cc/paper_files/paper/2025/file/5c1ddd2e59df46fd2aa85c833b1b36ed-Paper-Conference.pdf)
- [Parallelizing AI Coding Agents](https://ainativedev.io/news/how-to-parallelize-ai-coding-agents)
